This repository contains our implementation of the "Residual Attention Network for Image Classification" paper along with the project report. To run the code, simply execute the jupyter notebooks in the associated direcotries. 

Drive link to the trained models : https://drive.google.com/drive/folders/1af79537iF683vbbh5dGNSUg8xDQ8bNHR

The folder /CIFAR-10 contains the implementation of attention network on the CIFAR-10 dataset with batch size of 64 and 32.

The foler /CIFAR-100 contains the implementation of attention network on the CIFAR-100 dataset with batch size of 64 and 32.

The folder /ImageNet contains the implementation of attention network on the Tiny-ImageNet dataset

The folder /table contains the table comparing the performance of different network architectures on the datasets.

# Project tree

 * [CIFAR-10](./CIFAR-10)
   * [cifar_10_batch_size_32.ipynb](./CIFAR-10/cifar_10_batch_size_32.ipynb)
   * [cifar_10_batch_size_64.ipynb](./CIFAR-10/cifar_10_batch_size_64.ipynb)
   
 * [CIFAR-100](./CIFAR-100)
   * [cifar_100_batch_size_32.ipynb](./CIFAR-100/cifar_100_batch_size_32.ipynb)
   * [cifar_100_batch_size_64.ipynb](./CIFAR-100/cifar_100_batch_size_64.ipynb)
   
 * [table](./table)
   * [Table.PNG](./table/Table.PNG)
 
 * [E4040.2021FALL.YOYO.report.aa4821.bdd2115.vm2656.docx](./E4040.2021FALL.YOYO.report.aa4821.bdd2115.vm2656.docx)
